{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvJcUvweU_YE",
        "outputId": "f087db29-6e88-486f-cd2d-9048f9ae755f"
      },
      "outputs": [],
      "source": [
        "# access to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_KQqfjzdfLk",
        "outputId": "aeb5e0e6-c3ef-4996-af93-4e7f244b1883"
      },
      "outputs": [],
      "source": [
        "# create a directory in drive\n",
        "import os\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2cdEe0Id3mU",
        "outputId": "7a78977b-69d0-424c-fa2d-35067cf3ef51"
      },
      "outputs": [],
      "source": [
        "%cd \"/content/gdrive/MyDrive//2023ECGChallenge\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHItwXGVVxU8"
      },
      "source": [
        "### *load dataset*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEqh93qcVT6H"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "x_train = pd.read_csv('x_train_lead_3.csv', index_col= 0)\n",
        "y_train = pd.read_csv('y_train_lead_3.csv', index_col= 0)\n",
        "\n",
        "# print(x_train.shape)\n",
        "# print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhSCUA7dz-Im"
      },
      "outputs": [],
      "source": [
        "# mark accute/not accute\n",
        "y_train = np.array(y_train['not_accute'])\n",
        "y_train = y_train.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJvMj1cJoVBv"
      },
      "source": [
        "### *model creation*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au20BJsro1IK",
        "outputId": "81079f4d-e4de-494c-ef94-837f952be7d9"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGE1cTsxeyC8"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Dense, Dropout, Activation, BatchNormalization, Add\n",
        "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPool1D, ZeroPadding1D, LSTM, Bidirectional\n",
        "from keras.models import Sequential, Model\n",
        "from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from scipy import optimize\n",
        "from scipy.io import loadmat\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2LXVsSSodZV"
      },
      "source": [
        "#### *a. Lenet*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaPT7f5hoZcs"
      },
      "outputs": [],
      "source": [
        "lenet_5_model=Sequential()\n",
        "\n",
        "lenet_5_model.add(Conv1D(filters=6, kernel_size=3, padding='same', input_shape=(1000,1)))\n",
        "lenet_5_model.add(BatchNormalization())\n",
        "lenet_5_model.add(Activation('relu'))\n",
        "lenet_5_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n",
        "\n",
        "lenet_5_model.add(Conv1D(filters=16, strides=1, kernel_size=5))\n",
        "lenet_5_model.add(BatchNormalization())\n",
        "lenet_5_model.add(Activation('relu'))\n",
        "lenet_5_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n",
        "\n",
        "lenet_5_model.add(GlobalAveragePooling1D())\n",
        "\n",
        "lenet_5_model.add(Dense(64, activation='relu'))\n",
        "\n",
        "lenet_5_model.add(Dense(32, activation='relu'))\n",
        "\n",
        "lenet_5_model.add(Dense(1, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV_ke1h_gJZV",
        "outputId": "25b14ed2-39e5-412a-a1c4-e916f9561d91"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    # define simple learning rate decay\n",
        "    lr = 0.001 * math.pow(0.1, math.floor(epoch / 10))\n",
        "    return lr\n",
        "\n",
        "# print('Decaying Rate')\n",
        "# print(lr_schedule(9), lr_schedule(10), lr_schedule(19), lr_schedule(20))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsOVe2B4fh6N"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad\n",
        "\n",
        "# compile model\n",
        "lenet_5_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAnz0QNbfiJo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "filepath = \"best_model_resnet50.h5\"\n",
        "# define early_stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30)\n",
        "# define checkpoint\n",
        "model_checkpoint = ModelCheckpoint(filepath, save_best_only=True, save_weights_only=False, monitor='val_loss', mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzFWUWjRfiN6",
        "outputId": "151753dd-c463-4392-99f5-e8d94ee7b566"
      },
      "outputs": [],
      "source": [
        "# gpu usage\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "\n",
        "with tf.device(device_name):\n",
        "    history = lenet_5_model.fit(x=x_train,\n",
        "                          y=y_train,           \n",
        "                          validation_split= 0.1,\n",
        "                          batch_size=128,         \n",
        "                          epochs=200,            \n",
        "                          verbose=2,\n",
        "                        callbacks=[lr_scheduler, early_stopping, model_checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-XDmW0porII"
      },
      "source": [
        "#### *b. VGG 16*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkR2QN4-otGF"
      },
      "outputs": [],
      "source": [
        "vgg_16_model=Sequential()\n",
        "\n",
        "vgg_16_model.add(Conv1D(filters=64, kernel_size=3, padding='same',  input_shape=(1000,1)))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(Conv1D(filters=64, kernel_size=3, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n",
        "\n",
        "vgg_16_model.add(Conv1D(filters=128, kernel_size=3, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(Conv1D(filters=128, kernel_size=3, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n",
        "\n",
        "vgg_16_model.add(Conv1D(filters=256, kernel_size=3, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(Conv1D(filters=256, kernel_size=3, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(Conv1D(filters=256, kernel_size=3, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n",
        "\n",
        "vgg_16_model.add(Conv1D(filters=512, kernel_size=3, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(Conv1D(filters=512, kernel_size=3, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(Conv1D(filters=512, kernel_size=3, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n",
        "\n",
        "vgg_16_model.add(Conv1D(filters=512, kernel_size=3, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(Conv1D(filters=512, kernel_size=1, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(Conv1D(filters=512, kernel_size=1, padding='same'))\n",
        "vgg_16_model.add(BatchNormalization())\n",
        "vgg_16_model.add(Activation('relu'))\n",
        "vgg_16_model.add(MaxPool1D(pool_size=2, strides=2, padding='same'))\n",
        "\n",
        "vgg_16_model.add(GlobalAveragePooling1D())\n",
        "vgg_16_model.add(Dense(256, activation='relu'))\n",
        "vgg_16_model.add(Dropout(0.4))\n",
        "vgg_16_model.add(Dense(128, activation='relu'))\n",
        "vgg_16_model.add(Dropout(0.4))\n",
        "vgg_16_model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paP1gCUnotOj",
        "outputId": "913ae51f-cd02-4127-8739-f76aba6f3304"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    # define simple learning rate decay\n",
        "    lr = 0.001 * math.pow(0.1, math.floor(epoch / 10))\n",
        "    return lr\n",
        "\n",
        "# print('Decaying Rate')\n",
        "# print(lr_schedule(9), lr_schedule(10), lr_schedule(19), lr_schedule(20))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH1qaA0qotOl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad\n",
        "\n",
        "# compile model\n",
        "vgg_16_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh9Il2NSotOl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "filepath = \"best_model_vgg_16_model.h5\"\n",
        "# define early_stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30)\n",
        "# define checkpoint\n",
        "model_checkpoint = ModelCheckpoint(filepath, save_best_only=True, save_weights_only=False, monitor='val_loss', mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp2cTllVotOm",
        "outputId": "a52d0192-8391-41e8-8a6e-22dad458edb8"
      },
      "outputs": [],
      "source": [
        "# gpu usage\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "\n",
        "with tf.device(device_name):\n",
        "    history = vgg_16_model.fit(x=x_train,\n",
        "                          y=y_train,           \n",
        "                          validation_split= 0.1,\n",
        "                          batch_size=128,         \n",
        "                          epochs=200,            \n",
        "                          verbose=2,\n",
        "                        callbacks=[lr_scheduler, early_stopping, model_checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVxKatGkpgf4"
      },
      "source": [
        "#### *c. Inception*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scmpoO5JrEg2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGKi_qnIpgbw"
      },
      "outputs": [],
      "source": [
        "def inception_block(prev_layer):\n",
        "    \n",
        "    conv1=Conv1D(filters = 64, kernel_size = 1, padding = 'same')(prev_layer)\n",
        "    conv1=BatchNormalization()(conv1)\n",
        "    conv1=Activation('relu')(conv1)\n",
        "    \n",
        "    conv3=Conv1D(filters = 64, kernel_size = 1, padding = 'same')(prev_layer)\n",
        "    conv3=BatchNormalization()(conv3)\n",
        "    conv3=Activation('relu')(conv3)\n",
        "    conv3=Conv1D(filters = 64, kernel_size = 3, padding = 'same')(conv3)\n",
        "    conv3=BatchNormalization()(conv3)\n",
        "    conv3=Activation('relu')(conv3)\n",
        "    \n",
        "    conv5=Conv1D(filters = 64, kernel_size = 1, padding = 'same')(prev_layer)\n",
        "    conv5=BatchNormalization()(conv5)\n",
        "    conv5=Activation('relu')(conv5)\n",
        "    conv5=Conv1D(filters = 64, kernel_size = 5, padding = 'same')(conv5)\n",
        "    conv5=BatchNormalization()(conv5)\n",
        "    conv5=Activation('relu')(conv5)\n",
        "    \n",
        "    pool= MaxPool1D(pool_size=3, strides=1, padding='same')(prev_layer)\n",
        "    convmax=Conv1D(filters = 64, kernel_size = 1, padding = 'same')(pool)\n",
        "    convmax=BatchNormalization()(convmax)\n",
        "    convmax=Activation('relu')(convmax)\n",
        "    \n",
        "    layer_out = concatenate([conv1, conv3, conv5, convmax], axis=1)\n",
        "    \n",
        "    return layer_out\n",
        "\n",
        "def inception_model(input_shape):\n",
        "    X_input=Input(input_shape)\n",
        "    \n",
        "    X = ZeroPadding1D(3)(X_input)\n",
        "    \n",
        "    X = Conv1D(filters = 64, kernel_size = 7, padding = 'same')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPool1D(pool_size=3, strides=2, padding='same')(X)\n",
        "    \n",
        "    X = Conv1D(filters = 64, kernel_size = 1, padding = 'same')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    X = inception_block(X)\n",
        "    X = inception_block(X)\n",
        "    \n",
        "    X = MaxPool1D(pool_size=7, strides=2, padding='same')(X)\n",
        "    \n",
        "    X = GlobalAveragePooling1D()(X)\n",
        "    X = Dense(1,activation='sigmoid')(X)\n",
        "    \n",
        "    model = Model(inputs = X_input, outputs = X, name='Inception')\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF8pP3m8pm8U"
      },
      "outputs": [],
      "source": [
        "inception_model = inception_model(input_shape = (1000,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc2sihxlpnDG",
        "outputId": "c877e895-ed88-499d-e89f-66740912c048"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    # define simple learning rate decay\n",
        "    lr = 0.001 * math.pow(0.1, math.floor(epoch / 10))\n",
        "    return lr\n",
        "\n",
        "# print('Decaying Rate')\n",
        "# print(lr_schedule(9), lr_schedule(10), lr_schedule(19), lr_schedule(20))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6FKkFAspnDH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad\n",
        "\n",
        "# compile model\n",
        "inception_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5nUg8AkpnDI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "filepath = \"best_model_inception_model.h5\"\n",
        "# define early_stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30)\n",
        "# define checkpoint\n",
        "model_checkpoint = ModelCheckpoint(filepath, save_best_only=True, save_weights_only=False, monitor='val_loss', mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5Non--ypnDI",
        "outputId": "7c284836-487e-465f-a144-2657eac2f2e1"
      },
      "outputs": [],
      "source": [
        "# gpu usage\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "\n",
        "with tf.device(device_name):\n",
        "    history = inception_model.fit(x=x_train,\n",
        "                          y=y_train,           \n",
        "                          validation_split= 0.1,\n",
        "                          batch_size=128,         \n",
        "                          epochs=200,            \n",
        "                          verbose=2,\n",
        "                        callbacks=[lr_scheduler, early_stopping, model_checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9WCPS3AouCw"
      },
      "source": [
        "#### d. LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKE7XUlEowY5"
      },
      "outputs": [],
      "source": [
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(64, input_shape=(1000,1), return_sequences=True))\n",
        "lstm_model.add(LSTM(64))\n",
        "lstm_model.add(Dense(32, activation = 'relu'))\n",
        "lstm_model.add(Dropout(0.3))\n",
        "lstm_model.add(Dense(1, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVuiNO8Aowpt",
        "outputId": "8c14225e-7299-44ba-871e-2bb4dda5e684"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    # define simple learning rate decay\n",
        "    lr = 0.001 * math.pow(0.1, math.floor(epoch / 10))\n",
        "    return lr\n",
        "\n",
        "# print('Decaying Rate')\n",
        "# print(lr_schedule(9), lr_schedule(10), lr_schedule(19), lr_schedule(20))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS-IVEjUowpu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad\n",
        "\n",
        "# compile model\n",
        "lstm_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2myH9yBowpu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "filepath = \"best_model_lstm_model.h5\"\n",
        "# define early_stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30)\n",
        "# define checkpoint\n",
        "model_checkpoint = ModelCheckpoint(filepath, save_best_only=True, save_weights_only=False, monitor='val_loss', mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfF9iefMowpu",
        "outputId": "d3d1197c-bf97-4a47-8a88-62eeea9f6b64"
      },
      "outputs": [],
      "source": [
        "# gpu usage\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "\n",
        "with tf.device(device_name):\n",
        "    history = lstm_model.fit(x=x_train,\n",
        "                          y=y_train,           \n",
        "                          validation_split= 0.1,\n",
        "                          batch_size=128,         \n",
        "                          epochs=200,            \n",
        "                          verbose=2,\n",
        "                        callbacks=[lr_scheduler, early_stopping, model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd6z6t3qoxHb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKySOQbZoxMV"
      },
      "source": [
        "#### *e. GRU*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhMmTpXRox-G"
      },
      "outputs": [],
      "source": [
        "from keras.layers import GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5Zqrxilqd8w"
      },
      "outputs": [],
      "source": [
        "GRU_model = Sequential()\n",
        "GRU_model.add(GRU(64, input_shape=(1000,1), return_sequences=True))\n",
        "GRU_model.add(GRU(64))\n",
        "GRU_model.add(Dense(32, activation = 'relu'))\n",
        "GRU_model.add(Dropout(0.3))\n",
        "GRU_model.add(Dense(1, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ifSRRuPqd8x",
        "outputId": "4c6b2f31-e4ec-4d18-bc41-1fbc7cbf0f97"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import math\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    # define simple learning rate decay\n",
        "    lr = 0.001 * math.pow(0.1, math.floor(epoch / 10))\n",
        "    return lr\n",
        "\n",
        "# print('Decaying Rate')\n",
        "# print(lr_schedule(9), lr_schedule(10), lr_schedule(19), lr_schedule(20))\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bT_nkEJqd8y"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad\n",
        "\n",
        "# compile model\n",
        "GRU_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBM7K5BBqd8y"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "filepath = \"best_model_GRU_model.h5\"\n",
        "# define early_stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30)\n",
        "# define checkpoint\n",
        "model_checkpoint = ModelCheckpoint(filepath, save_best_only=True, save_weights_only=False, monitor='val_loss', mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpsmBmogqd8y",
        "outputId": "fea679cb-d7df-41ff-ab1a-4f845ee727b6"
      },
      "outputs": [],
      "source": [
        "# gpu usage\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "\n",
        "with tf.device(device_name):\n",
        "    history = GRU_model.fit(x=x_train,\n",
        "                          y=y_train,           \n",
        "                          validation_split= 0.1,\n",
        "                          batch_size=128,         \n",
        "                          epochs=200,            \n",
        "                          verbose=2,\n",
        "                        callbacks=[lr_scheduler, early_stopping, model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSQ54ZuErTun"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
